#%%def get_data():        import pandas as pd#     KAGGLE_PROJECT = 'ieee-fraud-detection'    SET_1 = 'transaction'    SET_2 = 'identity'    IDX_COL = 'TransactionID'    train_1 = pd.read_csv('../data/train_' + SET_1 + '.csv', index_col=IDX_COL, low_memory=True)    train_2 = pd.read_csv('../data/train_' + SET_2 + '.csv', index_col=IDX_COL, low_memory=True)    test_1  = pd.read_csv('../data/test_'  + SET_1 + '.csv', index_col=IDX_COL, low_memory=True)    test_2  = pd.read_csv('../data/test_'  + SET_2 + '.csv', index_col=IDX_COL, low_memory=True)    train = train_1.merge(train_2, how='left', left_index=True, right_index=True)    test  = test_1 .merge(test_2,  how='left', left_index=True, right_index=True)    test.columns = test.columns.str.replace("-", "_")    df = pd.concat([train, test])    return df# MERGE & UNIONdef merge_union():    # merge data and create 5 folds    import pandas as pd    # 18 seconds    train = pd.read_csv('../data/train_transaction.csv', index_col='TransactionID').merge(pd.read_csv('../data/train_identity.csv', index_col='TransactionID'), how='left', left_index=True, right_index=True)    train.columns = train.columns.str.replace("-", "_")        # 17 seconds    test  = pd.read_csv('../data/test_transaction.csv' , index_col='TransactionID').merge(pd.read_csv( '../data/test_identity.csv', index_col='TransactionID'), how='left', left_index=True, right_index=True)    test.columns = test.columns.str.replace("-", "_")        test.insert(0, 'isFraud', value=([-1] * test.shape[0]))    all = pd.concat([train, test])    del train, test        return all# REDUCE DATA SIZESdef minify(df, verbose=True, use_feather=True):    import numpy as np    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']    start_mem = df.memory_usage().sum() / 1024**2        for col in df.columns:        col_type = df[col].dtypes        if col_type in numerics:            c_min = df[col].min()            c_max = df[col].max()            if str(col_type)[:3] == 'int':                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:                    df[col] = df[col].astype(np.int8)                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:                    df[col] = df[col].astype(np.int16)                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:                    df[col] = df[col].astype(np.int32)                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:                    df[col] = df[col].astype(np.int64)              else:                if not use_feather and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:                    df[col] = df[col].astype(np.float16)                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:                    df[col] = df[col].astype(np.float32)                else:                    df[col] = df[col].astype(np.float64)        end_mem = df.memory_usage().sum() / 1024**2    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))    return df# COL TYPESdef col_types(df):    import numpy as np    import pandas as pd        cat_cols = []        for c in df.columns:        #if not np.issubdtype(df[c].dtype, np.number):                        cat_col_info = {}        cat_col_info['name'] = c        cat_col_info['n_unique'] = df[c].nunique()        cat_col_info['dtype'] = df[c].dtype        cat_cols.append(cat_col_info)    return pd.DataFrame.from_dict(cat_cols)      # ONE HOT ENCODEdef ohe_col(df, col):    df = pd.concat([df, pd.get_dummies(df[col], drop_first=True)], axis=1)    df = df.drop(columns=[col], axis=1)    return df# LABEL ENCODEdef le_col(df, col):    le = preprocessing.LabelEncoder()    le.fit(df[col])    print(list(le.classes_))    le.transform(df[col])    return df    # SAVE to DISK def save(df, path='../data/tain_test_min.ftr'):   df.reset_index().to_feather(path) # READ from DISKdef get_df(path='../data/tain_test_min.ftr', index_col='TransactionID'):    all = pd.read_feather(path).set_index(index_col)#%%#%%df = pd.concat([df, pd.get_dummies(df[col], drop_first=True)], axis=1)df = df.drop(columns=[col], axis=1)return dffor index, row in types[(types['n_unique'] < 8) & (types['dtype'] == 'object')].iterrows():    ohe_col = row['name']    print('ohe ', ohe_col)    all = ohe_cols(all, ohe_col)#%%for index, row in types[(types['n_unique'] >= 8) & (types['dtype'] == 'object')].iterrows():    le_col = row['name']    print(le_col)#%%#%%    # LABEL ENCODE#%%bin_num_df = all[bin_nums]del row, index#%%v1 = pd.get_dummies(all['V1'], drop_first=True)#%%# 2 secondsX = all[(all.isFraud >= 0)]del all#%%# CREATE FOLDS AND SAVEfrom sklearn.model_selection import KFoldkf = KFold(n_splits=5, shuffle=True, random_state=0)i = 0for train_index, test_index in kf.split(X):    print(i, "TRAIN:", train_index, "TEST:", test_index)    train_data = X.iloc[train_index]    train_data.reset_index().to_feather('../data/train_'+str(i)+'.ftr')        test_data  = X.iloc[test_index]    test_data.reset_index().to_feather('../data/test_'+str(i)+'.ftr')        i += 1#%%